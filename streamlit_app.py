# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EW7wuTHY-CwDlmS1XrFaqGlUk8miZS1u
"""

import numpy as np
import streamlit as st
import sklearn
import nltk
nltk.download('punkt')  # Add this line to download the 'punkt' resource
nltk.download('averaged_perceptron_tagger')  # Download the 'averaged_perceptron_tagger' resource for pos_tag
from nltk.tokenize import word_tokenize
import pandas as pd
import json

# Load your image files
demo_image_path = "demo.jpeg"
gif_image_path = "1.gif"

# Display demo.png image
st.image(demo_image_path, use_column_width=True)

# Load your neural network weights and biases
wei_prev = [6.53372226, 1.45266998, -1.31130261, -3.16864773, 0.39603089]
wei_cur = [1.74665619, -0.74696832, 2.84321548, -1.33783743]
wei_fb = [1.28461033]
wei_bias = [0.41829136]

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

def onehot_pos_cur(num):
    if num == 1:
        return np.array([0, 0, 0, 1])
    if num == 2:
        return np.array([0, 0, 1, 0])
    if num == 3:
        return np.array([0, 1, 0, 0])
    if num == 4:
        return np.array([1, 0, 0, 0])

def onehot_pos_prev(num):
    if num == 1:
        return np.array([0, 0, 0, 0, 1])
    if num == 2:
        return np.array([0, 0, 0, 1, 0])
    if num == 3:
        return np.array([0, 0, 1, 0, 0])
    if num == 4:
        return np.array([0, 1, 0, 0, 0])

# Define the mapping of part-of-speech tags to numeric values
pos_map = {
    "NN": 1,
    "DT": 2,
    "JJ": 3,
    "OT": 4
}

st.title("üå≤ Recurrent Perceptron for Noun Chunk Identification üå≤")

# Using Markdown for the input text to include an emoji
user_input = st.text_input("Enter a POS tagged input", "")

tokens = word_tokenize(user_input)

# Perform part-of-speech tagging
tagged_words = nltk.pos_tag(tokens)
print(tagged_words)

# Initialize a list to store filtered words
filtered_words = []

# Filter tagged words based on the given tags
for word, tag in tagged_words:
    if tag.startswith('NN'):
        filtered_words.append(pos_map["NN"])
    elif tag.startswith('DT'):
        filtered_words.append(pos_map["DT"])
    elif tag.startswith('JJ'):
        filtered_words.append(pos_map["JJ"])
    else:
        filtered_words.append(pos_map["OT"])

user_input = filtered_words

# Display the "Classify" button with larger size
classify_button = st.button(" Classify ", key="classify_button", help="Click to classify")

# Adjusting the size of the classify button using CSS
st.markdown(
    """
    <style>
    .stButton>button {
        width: 200px !important;
        height: 50px !important;
        font-size: 18px !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)
output = []
if classify_button:
    user_input = np.array(list(user_input), dtype=int)

    output = []
    for i in range(len(user_input)):
        if i == 0:
            x_prev = np.array([1, 0, 0, 0, 0])  # Initial previous POS tag (V)
            y_prev = 0  # Initial previous output
        else:
            x_prev = onehot_pos_prev(x_prev)  # Convert previous POS tag to one-hot vector

        x_cur_int = user_input[i]  # Current POS tag index
        x_cur = onehot_pos_cur(x_cur_int)  # Convert current POS tag to one-hot vector
    
        # Forward pass through the network using sigmoid activation function
        y_cur = sigmoid((np.dot(wei_fb, y_prev) + np.dot(wei_prev, x_prev) + np.dot(wei_cur, x_cur) - wei_bias).item())
    
        # Predict the label based on the output of the network
        if y_cur > 0.5:
            output.append(1)
        else:
            output.append(0)
    
        x_prev = x_cur_int
        y_prev = y_cur

    # Combine words and part-of-speech tags
    pos_tagged = [f"{word}_{pos_map.get(tag[:2], 'OT')}" for word, (_, tag) in zip(tokens, tagged_words)]
    pos_tagged_str = " ".join(pos_tagged)

    # Combine words, part-of-speech tags, and predicted labels
    chunk_result = [f"{word}_{pos_map.get(tag[:2], 'OT')}_{label}" for word, (_, tag), label in zip(tokens, tagged_words, output)]
    chunk_result_str = " ".join(chunk_result)
    
    # Display the results
    st.write("POS tagged:", pos_tagged_str)
    st.write("")  # Add an empty line for spacing
    st.write("Chunk:", chunk_result_str)

# Add the message below the Classify button
st.markdown("‚Ä¢ **Made by 4 IIT-Bombay students.**")
st.markdown("‚Ä¢Hosted by ‚ù§Ô∏è")

# Display 1.gif image
st.image(gif_image_path, use_column_width=True)
