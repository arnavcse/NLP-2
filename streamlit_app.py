# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EW7wuTHY-CwDlmS1XrFaqGlUk8miZS1u
"""

import numpy as np
import streamlit as st
import sklearn
import nltk
nltk.download('punkt')  # Add this line to download the 'punkt' resource
nltk.download('averaged_perceptron_tagger')  # Download the 'averaged_perceptron_tagger' resource for pos_tag
from nltk.tokenize import word_tokenize
import pandas as pd
import json

# Load your image files
demo_image_path = "demo.jpeg"
gif_image_path = "1.gif"

# Display demo.png image
st.image(demo_image_path, use_column_width=True)

# Load your neural network weights and biases
wei_prev = [6.53372226, 1.45266998, -1.31130261, -3.16864773, 0.39603089]
wei_cur = [1.74665619, -0.74696832, 2.84321548, -1.33783743]
wei_fb = [1.28461033]
wei_bias = [0.41829136]

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

def onehot_pos_cur(num):
    if num == 1:
        return np.array([0, 0, 0, 1])
    if num == 2:
        return np.array([0, 0, 1, 0])
    if num == 3:
        return np.array([0, 1, 0, 0])
    if num == 4:
        return np.array([1, 0, 0, 0])

def onehot_pos_prev(num):
    if num == 1:
        return np.array([0, 0, 0, 0, 1])
    if num == 2:
        return np.array([0, 0, 0, 1, 0])
    if num == 3:
        return np.array([0, 0, 1, 0, 0])
    if num == 4:
        return np.array([0, 1, 0, 0, 0])

# Function to map NLTK's POS tags to the simplified tags
def nltk_to_simple_pos(nltk_tag):
    nltk_mapping = {
        'NN': 'NN',
        'NNS': 'NN',
        'NNP': 'NN',
        'NNPS': 'NN',
        'DT': 'DT',
        'PDT': 'DT',
        'POS': 'DT',
        'JJ': 'JJ',
        'JJR': 'JJ',
        'JJS': 'JJ'
        # All other NLTK POS tags not listed here will default to 'OT' (Others)
    }
    return nltk_mapping.get(nltk_tag, 'OT')

st.title("üå≤ Recurrent Perceptron for Noun Chunk Identification üå≤")

# Using Markdown for the input text to include an emoji
user_input = st.text_input("Enter a POS tagged input", "")

tokens = word_tokenize(user_input)

# Perform part-of-speech tagging using NLTK
tagged_words = nltk.pos_tag(tokens)
print(tagged_words)

# Initialize a list to store filtered words and simplified POS tags
filtered_words = []
simplified_pos_tags = []

# Filter tagged words based on tags of interest and map to simplified tags
for word, tag in tagged_words:
    simplified_tag = nltk_to_simple_pos(tag)
    simplified_pos_tags.append(simplified_tag)
    if simplified_tag == 'NN':
        filtered_words.append(1)
    elif simplified_tag == 'DT':
        filtered_words.append(2)
    elif simplified_tag == 'JJ':
        filtered_words.append(3)
    else:
        filtered_words.append(4)

user_input = filtered_words

# Display the "Classify" button with larger size
classify_button = st.button(" Classify ", key="classify_button", help="Click to classify")

# Adjusting the size of the classify button using CSS
st.markdown(
    """
    <style>
    .stButton>button {
        width: 200px !important;
        height: 50px !important;
        font-size: 18px !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)
output = []
if classify_button:
    user_input = np.array(list(user_input), dtype=int)

    output = []
    for i in range(len(user_input)):
        if i == 0:
            x_prev = np.array([1, 0, 0, 0, 0])  # Initial previous POS tag (V)
            y_prev = 0  # Initial previous output
        else:
            x_prev = onehot_pos_prev(x_prev)  # Convert previous POS tag to one-hot vector

        x_cur_int = user_input[i]  # Current POS tag index
        x_cur = onehot_pos_cur(x_cur_int)  # Convert current POS tag to one-hot vector
    
        # Forward pass through the network using sigmoid activation function
        y_cur = sigmoid((np.dot(wei_fb, y_prev) + np.dot(wei_prev, x_prev) + np.dot(wei_cur, x_cur) - wei_bias).item())
    
        # Predict the label based on the output of the network
        if y_cur > 0.5:
            output.append(1)
        else:
            output.append(0)
    
        x_prev = x_cur_int
        y_prev = y_cur

    # Combine words and simplified POS tags
    pos_tagged_str = " ".join([f"{word}_{tag}" for word, tag in zip(tokens, simplified_pos_tags)])

    # Combine words, simplified POS tags, and predicted labels
    chunk_result_str = " ".join([f"{word}_{tag}_{label}" for word, tag, label in zip(tokens, simplified_pos_tags, output)])
    
    # Display the POS tagged and chunk result
    st.write("POS tagged:", pos_tagged_str)
    st.write("")  # Add an empty line for spacing
    st.write("Chunk:", chunk_result_str)

# Add the message below the Classify button
st.markdown("‚Ä¢ **Made by 4 IIT-Bombay students.**")
st.markdown("‚Ä¢Hosted by ‚ù§Ô∏è")

# Display 1.gif image
st.image(gif_image_path, use_column_width=True)
